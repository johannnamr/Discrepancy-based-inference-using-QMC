{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Utils.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnSXRhjgQlD6DJQdyqJtBu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johannnamr/Discrepancy-based-inference-using-QMC/blob/main/Helper-functions/Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJO6sGdALLLN"
      },
      "source": [
        "# Utils\n",
        "\n",
        "Notebook containing all necessary functions for the conducted analyses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlQ1uY0dLLHs"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckgt-0izogiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6a0400-c216-42d4-99cf-cc1fce21fa8b"
      },
      "source": [
        "! pip install --upgrade pip # update pip to latest version\n",
        "! pip install qmcpy --quiet\n",
        "! pip install pytictoc --quiet\n",
        "! pip install POT --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/eb/4a3642e971f404d69d4f6fa3885559d67562801b99d7592487f1ecc4e017/pip-20.3.3-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.3.3\n",
            "  Building wheel for qmcpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux96VUALLGg5"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats # used for inverse Gaussian\n",
        "import scipy.spatial.distance as distance # distance used for kernel\n",
        "from sklearn.gaussian_process.kernels import Matern # Matern kernel\n",
        "import qmcpy # QMC points\n",
        "from pytictoc import TicToc # timer\n",
        "import ot # Wasserstein distance and Sinkhorn divergence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9oeOa4IwVh1"
      },
      "source": [
        "# autodiff\n",
        "import jax.numpy as jnp\n",
        "from jax import jacfwd\n",
        "from jax import ops\n",
        "from jax import lax\n",
        "from copy import deepcopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUX1xSus8C7j"
      },
      "source": [
        "## Inverse Gaussian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHp8xE6j_E4i"
      },
      "source": [
        "Function generating standard normals using the inverse of the univariate Gaussian CDF: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nPrsdzQ8IBE"
      },
      "source": [
        "def normals_inv(u):\n",
        "  # avoid origin\n",
        "  u[u==0] = np.nextafter(0, 1)\n",
        "  # create standard normal samples\n",
        "  z = stats.norm.ppf(u, loc=0, scale=1)\n",
        "  return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIc01F0ANpRf"
      },
      "source": [
        "## Box-Muller transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RC2igG8NyGX"
      },
      "source": [
        "Box-Muller transformation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIMjA1XZNulw"
      },
      "source": [
        "def boxmuller(unif1,unif2):\n",
        "  u1 = np.sqrt(-2*np.log(unif1))*np.cos(2*np.pi*unif2)\n",
        "  u2 = np.sqrt(-2*np.log(unif1))*np.sin(2*np.pi*unif2)\n",
        "  return np.transpose(np.vstack([u1,u2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EwcmZhwOSWD"
      },
      "source": [
        "Function generating standard normals using the box-muller transformation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hLV50nGOBoX"
      },
      "source": [
        "def normals(n, d, unif, sv=False):\n",
        "\n",
        "    # avoid origin\n",
        "    unif[unif==0] = np.nextafter(0, 1)\n",
        "\n",
        "    # if d is odd, add one dimension\n",
        "    if d % 2 != 0:\n",
        "      dim = d + 1\n",
        "    else:\n",
        "      dim = d\n",
        "\n",
        "    # expand dimensions for SV model\n",
        "    if sv == True:\n",
        "      dim = 2+2*d\n",
        "\n",
        "    # create standard normal samples\n",
        "    u = np.zeros((n,dim))\n",
        "    for i in np.arange(0,dim,2):\n",
        "      u[:,i:(i+2)] = boxmuller(unif[:,i],unif[:,(i+1)])\n",
        "\n",
        "    # if d is odd, drop one dimension\n",
        "    if d % 2 != 0 or sv == True:\n",
        "      u = np.delete(u,-1,1)\n",
        "\n",
        "    return u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmyWGjY4MAuB"
      },
      "source": [
        "## Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiKVEKGNNRS4"
      },
      "source": [
        "Gaussian kernel $k(x,y)$, its gradient w.r.t. first element $\\nabla_1k(x,y)$ and its second derivative w.r.t. to the second and first argument $\\nabla_2\\nabla_1k(x,y)$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRLFC1vaUtVL"
      },
      "source": [
        "def k(x,y,kernel,l,c,b,nu,grad=True,sparse=False): \n",
        "\n",
        "    if sparse == True:\n",
        "      x = x.astype('float32')\n",
        "      y = y.astype('float32')\n",
        "    \n",
        "    # dimensions\n",
        "    d = x.shape[1]\n",
        "    dims = np.arange(d)\n",
        "    \n",
        "    if kernel=='gaussian':\n",
        "      # kernel\n",
        "      r = distance.cdist(x,y,'sqeuclidean')\n",
        "      K = np.exp(-(1/(2*l**2))*r)\n",
        "      if grad:\n",
        "        # first derivative\n",
        "        K_extended = K[np.newaxis,:,:]\n",
        "        diff_extended = (x[np.newaxis,:]-y[:,np.newaxis])\n",
        "        diff_extended = np.swapaxes(diff_extended,0,2)\n",
        "        grad_1 = -1*diff_extended*(1/l**2)*K_extended\n",
        "        # second derivative\n",
        "        diff_diffT = np.einsum('inm,jnm->ijnm',diff_extended,diff_extended)\n",
        "        grad_21 = (1/l**2)*(np.eye(d)[:,:,np.newaxis,np.newaxis]-diff_diffT*(1/l**2))*K\n",
        "\n",
        "    if kernel=='imq':\n",
        "      # kernel\n",
        "      r = distance.cdist(x,y,'sqeuclidean')\n",
        "      K = (c**2+r)**b\n",
        "      if grad:\n",
        "        # first derivative\n",
        "        r_extended = r[np.newaxis,:,:]\n",
        "        diff_extended = (x[np.newaxis,:]-y[:,np.newaxis])\n",
        "        diff_extended = np.swapaxes(diff_extended,0,2)\n",
        "        grad_1 = 2.*diff_extended*b*(c**2+r_extended)**(b-1.)\n",
        "        # second derivative\n",
        "        diagonal = -4.*b*(b-1.)*(diff_extended**2)*((c**2+r_extended)**(b-2.))-2.*b*((c**2+r_extended)**(b-1.))\n",
        "        diff_diffT = np.einsum('inm,jnm->ijnm',diff_extended,diff_extended)\n",
        "        grad_21 = -4.*b*(b-1.)*diff_diffT*np.power(c**2+r_extended[np.newaxis:,:,:],b-2.)\n",
        "        grad_21[range(d),range(d),:,:] = diagonal\n",
        "    \n",
        "    if kernel=='matern':\n",
        "      km = Matern(length_scale=l,nu=nu)\n",
        "      K = km(x,y)\n",
        "\n",
        "    if grad:\n",
        "      return list([K, grad_1, grad_21])\n",
        "    else:\n",
        "      return list([K])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-jw-IhkMWGX"
      },
      "source": [
        "## MMD$^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_BAVDT_Mek6"
      },
      "source": [
        "MMD$^2$ approximation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kVwc-SbMVQ_"
      },
      "source": [
        "def MMD_approx(n,m,kxx,kxy,kyy,stat_type='v'):\n",
        "  if stat_type=='u':\n",
        "    # first sum\n",
        "    np.fill_diagonal(kxx, np.repeat(0,n))\n",
        "    sum1 = np.sum(kxx)\n",
        "    \n",
        "    # second sum\n",
        "    sum2 = np.sum(kxy)\n",
        "    \n",
        "    # third sum\n",
        "    np.fill_diagonal(kyy, np.repeat(0,m))\n",
        "    sum3 = np.sum(kyy)\n",
        "    \n",
        "    return (1/(n*(n-1)))*sum1-(2/(m*n))*sum2+(1/(m*(m-1)))*sum3\n",
        "    \n",
        "  if stat_type=='v':\n",
        "    # first sum\n",
        "    np.fill_diagonal(kxx, np.repeat(0,n))\n",
        "    sum1 = np.sum(kxx)\n",
        "    \n",
        "    # second sum\n",
        "    sum2 = np.sum(kxy)\n",
        "    \n",
        "    # third sum\n",
        "    np.fill_diagonal(kyy, np.repeat(0,m))\n",
        "    sum3 = np.sum(kyy)\n",
        "    \n",
        "    return (1/n**2)*sum1-(2/(m*n))*sum2+(1/m**2)*sum3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeietpK3Mi3P"
      },
      "source": [
        "MMD$^2$ gradient $\\hat{J}$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4fjVkilMwBh"
      },
      "source": [
        "def grad_MMD(p,n,m,grad_g,k1xx,k1xy,stat_type='v'):\n",
        "    \n",
        "    if stat_type == 'u':\n",
        "      # first sum\n",
        "      prod1 = np.squeeze(np.einsum('ilj,imjk->lmjk', grad_g, np.expand_dims(k1xx,axis=1)))\n",
        "      if prod1.ndim==2:\n",
        "        np.fill_diagonal(prod1[:,:], 0)\n",
        "        sum1 = np.sum(prod1)\n",
        "      else:\n",
        "        for i in range(p):\n",
        "          np.fill_diagonal(prod1[i,:,:], 0)\n",
        "        sum1 = np.einsum('ijk->i',prod1)\n",
        "    \n",
        "      # second sum\n",
        "      prod2 = np.squeeze(np.einsum('ilj,imjk->lmjk', grad_g, np.expand_dims(k1xy,axis=1)))\n",
        "      if prod2.ndim==2:\n",
        "        sum2 = np.sum(prod2)\n",
        "      else:\n",
        "        sum2 = np.einsum('ijk->i',prod2)\n",
        "    \n",
        "      return (2/(n*(n-1)))*sum1-(2/(n*m))*sum2\n",
        "\n",
        "    if stat_type == 'v':\n",
        "      # first sum\n",
        "      prod1 = np.squeeze(np.einsum('ilj,imjk->lmjk', grad_g, np.expand_dims(k1xx,axis=1)))\n",
        "      if prod1.ndim==2:\n",
        "        np.fill_diagonal(prod1[:,:], 0)\n",
        "        sum1 = np.sum(prod1)\n",
        "      else:\n",
        "        for i in range(p):\n",
        "          np.fill_diagonal(prod1[i,:,:], 0)\n",
        "        sum1 = np.einsum('ijk->i',prod1)\n",
        "    \n",
        "      # second sum\n",
        "      prod2 = np.squeeze(np.einsum('ilj,imjk->lmjk', grad_g, np.expand_dims(k1xy,axis=1)))\n",
        "      if prod2.ndim==2:\n",
        "        sum2 = np.sum(prod2)\n",
        "      else:\n",
        "        sum2 = np.einsum('ijk->i',prod2)\n",
        "    \n",
        "      return (2/n**2)*sum1-(2/(n*m))*sum2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LvGBN7TM8Na"
      },
      "source": [
        "## Information metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyS2x9I_NMR0"
      },
      "source": [
        "Approximation of the informatin metric $g_U(\\theta)$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQzAWRijNAfW"
      },
      "source": [
        "def g_approx(p,n,grad_g,k21xx):\n",
        "    \n",
        "    # sum\n",
        "    grad_g_T = np.einsum('ijk -> jik',grad_g)\n",
        "    prod1 = np.einsum('ijk, jlkm -> ilkm', grad_g_T, k21xx)\n",
        "    prod2 = np.einsum('ijkl,jmk->imkl', prod1, grad_g)\n",
        "    for i in range(p):\n",
        "        np.fill_diagonal(prod2[i,i,:,:], 0)\n",
        "    gsum = np.einsum('ijkl->ij', prod2)\n",
        "    \n",
        "    return 1/(n*(n-1))*gsum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mXMhuXAMEtl"
      },
      "source": [
        "## Generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU7QLwzeY5Tl"
      },
      "source": [
        "Generator $G_\\theta(u)$ for the **uniform distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU77ob_IY-5Z"
      },
      "source": [
        "# generator\n",
        "def gen_unif(u):\n",
        "  return u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCpyNp-hNdFA"
      },
      "source": [
        "Generator $G_\\theta(u)$ and generator gradient $\\nabla_\\theta G_\\theta(u)$ for the **Gaussian distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM6GBykWMHL-"
      },
      "source": [
        "# generator using Box-Muller transform\n",
        "def gen_gaussian(n, d, unif, theta, sigma):\n",
        "\n",
        "  unif[unif==0] = np.nextafter(0, 1)\n",
        "\n",
        "  # if d is odd, add one dimension\n",
        "  if d % 2 != 0:\n",
        "    dim = d + 1\n",
        "  else:\n",
        "    dim = d\n",
        "\n",
        "  # create standard normal samples\n",
        "  u = np.zeros((n,dim))\n",
        "  for i in np.arange(0,dim,2):\n",
        "    u[:,i:(i+2)] = boxmuller(unif[:,i],unif[:,(i+1)])\n",
        "\n",
        "  # if d is odd, drop one dimension\n",
        "  if d % 2 != 0:\n",
        "    u = np.delete(u,-1,1)\n",
        "\n",
        "  # generate samples\n",
        "  x = theta + u*sigma\n",
        "\n",
        "  return x\n",
        "\n",
        "# gradient of the generator\n",
        "def grad_gen_gaussian(n, theta):\n",
        "    return np.broadcast_to(np.expand_dims(np.eye(theta.shape[0]),axis=2),(theta.shape[0],theta.shape[0],n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov3DwLck_Kfm"
      },
      "source": [
        "# generator using inverse transform\n",
        "def gen_gaussian_inv(n, d, unif, theta, sigma):\n",
        "\n",
        "  unif[unif==0] = np.nextafter(0, 1)\n",
        "\n",
        "  u = stats.norm.ppf(unif, loc=0, scale=1)\n",
        "\n",
        "  # generate samples\n",
        "  x = theta + u*sigma\n",
        "\n",
        "  return x\n",
        "\n",
        "# gradient of the generator\n",
        "def grad_gen_gaussian(n, theta):\n",
        "    return np.broadcast_to(np.expand_dims(np.eye(theta.shape[0]),axis=2),(theta.shape[0],theta.shape[0],n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF4J_XN6PTtV"
      },
      "source": [
        "Generator $G_\\theta(u)$ and generator gradient $\\nabla_\\theta G_\\theta(u)$ for the **g-and-k distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkTi6hvPYdS"
      },
      "source": [
        "# generator\n",
        "def gen_gandk(z, theta):\n",
        "  a = theta[0]\n",
        "  b = theta[1]\n",
        "  g = theta[2]\n",
        "  k = np.exp(theta[3])\n",
        "  x = a+b*(1+0.8*((1-np.exp(-g*z))/(1+np.exp(-g*z))))*((1+z**2)**(k))*z\n",
        "  return x\n",
        "\n",
        "# gradient of the generator\n",
        "def grad_gen_gandk(z,theta):\n",
        "    a = theta[0]\n",
        "    b = theta[1]\n",
        "    g = theta[2]\n",
        "    k = np.exp(theta[3])\n",
        "    grad1 = np.ones(z.shape[0])\n",
        "    grad2 = (1+(4/5)*((1-np.exp(-g*z))/(1+np.exp(-g*z))))*(np.exp(k*np.log(1+z**2)))*z\n",
        "    grad3 = (8/5)*theta[1]*((np.exp(g*z))/(1+np.exp(g*z))**2)*(np.exp(k*np.log(1+z**2)))*z**2\n",
        "    grad4 = b*(1+0.8*((1-np.exp(-g*z))/(1+np.exp(-g*z))))*(np.exp(k*np.log(1+z**2)))*np.log(1+z**2)*z\n",
        "    return np.expand_dims(np.einsum('ij->ji',np.c_[grad1,grad2,grad3,grad4]), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OdNshcfvfin"
      },
      "source": [
        "Generator $G_\\theta(u)$ and its gradient $\\nabla_\\theta G_\\theta(u)$ for **multivariate g-and-k distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MbX1ulxjMsr"
      },
      "source": [
        "# generator that can be differentiated using jax\n",
        "def gen_mvgandk_fct(z, theta):\n",
        "  a = theta[0]\n",
        "  b = theta[1]\n",
        "  g = theta[2]\n",
        "  k = theta[3]\n",
        "  t = theta[4]\n",
        "\n",
        "  d = z.shape[1]\n",
        "  if d>1:\n",
        "    # loop over i\n",
        "    def body_fun2(i,sqrtsigma):\n",
        "      # loop over j\n",
        "      def body_fun1(j,sqrtsigma):\n",
        "        # inner loop\n",
        "        def body_fun(l,curr):\n",
        "          curr = curr + jnp.sqrt(1+2*t*jnp.cos((l*jnp.pi)/(d+1)))*jnp.sin((i*l*jnp.pi)/(d+1))*jnp.sin((j*l*jnp.pi)/(d+1))\n",
        "          return curr\n",
        "        sqrtsigma = ops.index_update(sqrtsigma,ops.index[i-1,j-1],jnp.squeeze(lax.fori_loop(1, d+1, body_fun,jnp.array([0.]))))\n",
        "        return sqrtsigma\n",
        "      sqrtsigma = ops.index_update(sqrtsigma,ops.index[i-1,:],lax.fori_loop(1, d+1, body_fun1,sqrtsigma)[i-1,:])\n",
        "      return sqrtsigma\n",
        "    sqrtsigma = lax.fori_loop(1, d+1, body_fun2, jnp.zeros([d,d]))\n",
        "    sqrtsigma = sqrtsigma*(2/(d+1))\n",
        "    z = jnp.einsum('ij,lj->li',sqrtsigma,z)\n",
        "\n",
        "  x = a+b*(1+0.8*((1-jnp.exp(-g*z))/(1+jnp.exp(-g*z))))*((1+z**2)**(k))*z\n",
        "  return x\n",
        "\n",
        "# generator to avoid numerical instabilities\n",
        "def gen_mvgandk(z, theta):\n",
        "  theta_gen = deepcopy(theta)\n",
        "  theta_gen[3] = np.exp(theta[3])\n",
        "  x = gen_mvgandk_fct(z, theta_gen)\n",
        "  return x\n",
        "\n",
        "# gradient of generator avoiding numerical instabilities\n",
        "def grad_gen_mvgandk(z,theta):\n",
        "  grad_fct = jacfwd(gen_mvgandk_fct,1)\n",
        "  theta_gen = deepcopy(theta)\n",
        "  theta_gen[3] = np.exp(theta[3])\n",
        "  grad = grad_fct(z,theta_gen)\n",
        "  return np.einsum('ijl->jli',grad) # dimensions: [d,p,n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVrXDWntkdit"
      },
      "source": [
        "Generator $G_\\theta(u)$ for the **bivariate beta distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lufxtw6RnfiS"
      },
      "source": [
        "def sample_qmc_gamma(alpha,n):\n",
        "\n",
        "  'Function to simulate from a gamma distribution with \\alpha<1 and \\beta=1 using QMC points'\n",
        "\n",
        "  # get b\n",
        "  b = (alpha+np.e)/np.e\n",
        "\n",
        "  # fix QMC sequence\n",
        "  qmc = qmcpy.Halton(3)\n",
        "\n",
        "  # generate samples\n",
        "  i = 0\n",
        "  num = 0\n",
        "  gamma = np.array([])\n",
        "  while num < n:\n",
        "    # get qmc samples\n",
        "    omega = np.squeeze(qmc.gen_samples(n_min=i,n_max=i+1))\n",
        "    #omega = np.squeeze(qmcpy.Halton(3).gen_samples(1))\n",
        "    #omega = np.random.rand(3)\n",
        "    # accept-reject algorihtm\n",
        "    y = b*omega[0]\n",
        "    if y<=1:\n",
        "      x = y**(1/alpha)\n",
        "      #print(x)\n",
        "      w = -np.log(omega[1])\n",
        "      #print(w)\n",
        "      if w>=x:\n",
        "        gamma = np.append(gamma,x)\n",
        "        num += 1 # counts accepted points\n",
        "    else:\n",
        "      x = -np.log((b-y)/alpha)\n",
        "      w = omega[2]**(1/(alpha-1))\n",
        "      if w>=x:\n",
        "        gamma = np.append(gamma,x)\n",
        "        num += 1 # counts accepted points\n",
        "    i += 1 # counts number of simulated points\n",
        "\n",
        "  return gamma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ_hjhC9Vhh4"
      },
      "source": [
        "def sample_qmc_gamma(alpha,n):\n",
        "\n",
        "  'Function to simulate from a gamma distribution with \\alpha<1 and \\beta=1 using QMC points'\n",
        "\n",
        "  # get b\n",
        "  b = (alpha+np.e)/np.e\n",
        "\n",
        "  # fix QMC sequence\n",
        "  qmc = qmcpy.Halton(3)\n",
        "\n",
        "  # generate samples\n",
        "  i = 0\n",
        "  num = 0\n",
        "  gamma = np.array([])\n",
        "  while num < n:\n",
        "    # get qmc samples\n",
        "    omega = np.squeeze(qmc.gen_samples(n_min=i,n_max=i+1))\n",
        "    # accept-reject algorihtm\n",
        "    y = b*omega[0]\n",
        "    if y<=1:\n",
        "      x = y**(1/alpha)\n",
        "      if omega[1]<=np.e**(-x):\n",
        "        gamma = np.append(gamma,x)\n",
        "        num += 1 # counts accepted points\n",
        "    else:\n",
        "      x = -np.log((b-y)/alpha)\n",
        "      if omega[2]<=x**(alpha-1):\n",
        "        gamma = np.append(gamma,x)\n",
        "        num += 1 # counts accepted points\n",
        "    i += 1 # counts number of simulated points\n",
        "\n",
        "  return gamma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVytyduL2xbW"
      },
      "source": [
        "def gen_bibeta(theta, unif, qmc_gamma=False):\n",
        "  # number of samples\n",
        "  n = unif.shape[0]\n",
        "\n",
        "  # split theta into integer and decimal parts\n",
        "  i_theta,d_theta = divmod(theta,np.ones(5)) \n",
        "  i_theta = i_theta.astype(int)\n",
        "\n",
        "  # initialise\n",
        "  utild = np.zeros([n,5])\n",
        "  x = np.zeros((n,2))\n",
        "\n",
        "  # logs on uniforms\n",
        "  logunif = np.log(unif)\n",
        "\n",
        "  # get \\tilde{u}\n",
        "  j=0\n",
        "  for i in range(5):\n",
        "    sum = np.zeros(n)\n",
        "    if i_theta[i]!=0:\n",
        "      for k in range(i_theta[i]):\n",
        "        sum[:] += logunif[:,k+j]\n",
        "      utild[:,i] = -sum\n",
        "    if d_theta[i]!=0:\n",
        "      if qmc_gamma:\n",
        "        utild[:,i] += sample_qmc_gamma(d_theta[i],n)\n",
        "      else:\n",
        "        utild[:,i] += np.random.gamma(d_theta[i],1,n)\n",
        "    j += i_theta[i]\n",
        "\n",
        "  # generator\n",
        "  x1 = np.sum(np.vstack([utild[:,0],utild[:,2]]),axis=0)/np.sum(np.vstack([utild[:,0],utild[:,2],utild[:,3],utild[:,4]]),axis=0)\n",
        "  x2 = np.sum(np.vstack([utild[:,1],utild[:,3]]),axis=0)/np.sum(np.vstack([utild[:,1],utild[:,2],utild[:,3],utild[:,4]]),axis=0)\n",
        "\n",
        "  return np.vstack([x1,x2]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txM_du5EWV76"
      },
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egyZNeIdbdPD"
      },
      "source": [
        "Function to sample from **uniform distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xFY03c8bmdm"
      },
      "source": [
        "def sample_unif(method_sampling,n,d,sobol=False):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "  ' as either Halton, Sobol or Lattice points                               '\n",
        "\n",
        "  if method_sampling == 'MC':\n",
        "    unif = np.random.rand(n,d)\n",
        "  if method_sampling == 'QMC':\n",
        "    unif = qmc.gen_samples(n)\n",
        "  if method_sampling == 'RQMC':\n",
        "    if sobol:\n",
        "      unif = qmcpy.Sobol(d).gen_samples(n)\n",
        "    else:\n",
        "      unif = qmcpy.Halton(d).gen_samples(n)\n",
        "\n",
        "  # generate samples\n",
        "  x = gen_unif(unif)  \n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTmGNwWGcmRr"
      },
      "source": [
        "Function to sample $R$-times for MC and RQMC from **uniform distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Ql2G8DcmRs"
      },
      "source": [
        "def sample_unif_r(n,num,d,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "  ' as either Halton, Sobol or Lattice points                               '\n",
        "\n",
        "  # generate n data points using MC and RQMC\n",
        "  x_mc = np.zeros((num,np.max(n),d))\n",
        "  x_rqmc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(np.max(n),d)\n",
        "    if lattice:\n",
        "      if order==1:\n",
        "        unif_rqmc = qmcpy.Lattice(d).gen_samples(np.max(n))\n",
        "      if order==2:\n",
        "        unif_rqmc = qmcpy.Lattice(d,z_path=z_path+'lattice_vec.600.20.npy').gen_samples(np.max(n))\n",
        "      if order==8:\n",
        "        unif_rqmc = qmcpy.Lattice(d,z_path=z_path+'lattice_vec.600.13.npy').gen_samples(np.max(n))\n",
        "    else:\n",
        "      if sobol:\n",
        "        unif_rqmc = qmcpy.Sobol(d).gen_samples(np.max(n))\n",
        "      else:\n",
        "        unif_rqmc = qmcpy.Halton(d).gen_samples(np.max(n))\n",
        "    x_mc[r,:,:] = gen_unif(unif_mc)\n",
        "    x_rqmc[r,:,:] = gen_unif(unif_rqmc)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(np.max(n))\n",
        "  x_qmc = gen_unif(unif_qmc)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rajGtkJeUAVN"
      },
      "source": [
        "Function to sample $R$-times for MC and RQMC with varying $d$ from **uniform distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RssmPk2sUAVN"
      },
      "source": [
        "def sample_unif_r_d(n,num,d,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "  ' as either Halton, Sobol or Lattice points                               '\n",
        "\n",
        "  # generate n data points using MC and RQMC\n",
        "  x_mc = np.zeros((num,n,np.max(d)))\n",
        "  x_rqmc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(n,np.max(d))\n",
        "    if lattice:\n",
        "      if order==1:\n",
        "        unif_rqmc = qmcpy.Lattice(np.max(d)).gen_samples(n)\n",
        "      if order==2:\n",
        "        unif_rqmc = qmcpy.Lattice(np.max(d),z_path=z_path+'lattice_vec.600.20.npy').gen_samples(n)\n",
        "      if order==8:\n",
        "        unif_rqmc = qmcpy.Lattice(np.max(d),z_path=z_path+'lattice_vec.600.13.npy').gen_samples(n)\n",
        "    else:\n",
        "      if sobol:\n",
        "        unif_rqmc = qmcpy.Sobol(np.max(d)).gen_samples(n)\n",
        "      else:\n",
        "        unif_rqmc = qmcpy.Halton(np.max(d)).gen_samples(n)\n",
        "    x_mc[r,:,:] = gen_unif(unif_mc)\n",
        "    x_rqmc[r,:,:] = gen_unif(unif_rqmc)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(n)\n",
        "  x_qmc = gen_unif(unif_qmc)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53HlW2e5WZEi"
      },
      "source": [
        "Function to sample from **Gaussian distribution**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfTJQgrZWfHe"
      },
      "source": [
        "def sample_gaussian(method_sampling,n,d,s,theta,sobol=False):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc or qmc_1 sequence have to be fixed before using this function   '\n",
        "\n",
        "  # odd number of parameters\n",
        "  if d % 2 != 0: \n",
        "    if method_sampling == 'MC':\n",
        "      unif = np.random.rand(n,d+1)\n",
        "    if method_sampling == 'QMC':\n",
        "      unif = qmc_1.gen_samples(n)\n",
        "    if method_sampling == 'RQMC':\n",
        "      if sobol:\n",
        "        unif = qmcpy.Sobol(d+1).gen_samples(n)\n",
        "      else:\n",
        "        unif = qmcpy.Halton(d+1).gen_samples(n)\n",
        "\n",
        "  # even number of parameters\n",
        "  else: \n",
        "    if method_sampling == 'MC':\n",
        "      unif = np.random.rand(n,d)\n",
        "    if method_sampling == 'QMC':\n",
        "      unif = qmc.gen_samples(n)\n",
        "    if method_sampling == 'RQMC':\n",
        "      if sobol:\n",
        "        unif = qmcpy.Sobol(d).gen_samples(n)\n",
        "      else:\n",
        "        unif = qmcpy.Halton(d).gen_samples(n)\n",
        "\n",
        "  # use generator  \n",
        "  x = gen_gaussian(n,d,unif,theta,s)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLFF6UD6Hr8E"
      },
      "source": [
        "def sample_gaussian_inv(method_sampling,n,d,s,theta,sobol=False):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function   '\n",
        "\n",
        "  if method_sampling == 'MC':\n",
        "    unif = np.random.rand(n,d)\n",
        "  if method_sampling == 'QMC':\n",
        "    unif = qmc.gen_samples(n)\n",
        "  if method_sampling == 'RQMC':\n",
        "    if sobol:\n",
        "      unif = qmcpy.Sobol(d).gen_samples(n)\n",
        "    else:\n",
        "      unif = qmcpy.Halton(d).gen_samples(n)\n",
        "\n",
        "  # use generator  \n",
        "  x = gen_gaussian_inv(n,d,unif,theta,s)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtvjSmfpYDcK"
      },
      "source": [
        "Function to sample $R$-times for MC and RQMC from **Gaussian distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9gpGTcxYOIo"
      },
      "source": [
        "def sample_gaussian_r(n,num,d,s,theta,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc or qmc_1 sequence have to be fixed before using this function   '\n",
        "\n",
        "  # MC\n",
        "  x_mc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    # odd number of parameters\n",
        "    if d % 2 != 0: \n",
        "      unif_mc = np.random.rand(np.max(n),d+1)\n",
        "    # even number of parameters\n",
        "    else: \n",
        "      unif_mc = np.random.rand(np.max(n),d)\n",
        "    x = gen_gaussian(np.max(n),d,unif_mc,theta,s)\n",
        "    x_mc[r,:,:] = x\n",
        "\n",
        "  # QMC\n",
        "  # odd number of parameters\n",
        "  if d % 2 != 0: \n",
        "    unif_qmc = qmc_1.gen_samples(np.max(n))\n",
        "  # even number of parameters\n",
        "  else: \n",
        "    unif_qmc = qmc.gen_samples(np.max(n))\n",
        "  x_qmc = gen_gaussian(np.max(n),d,unif_qmc,theta,s)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    # odd number of parameters\n",
        "    if d % 2 != 0: \n",
        "      if lattice:\n",
        "        if order==1:\n",
        "          unif_rqmc = qmcpy.Lattice(d+1).gen_samples(np.max(n))\n",
        "        if order==2:\n",
        "          unif_rqmc = qmcpy.Lattice(d+1,z_path=z_path+'lattice_vec.600.20.npy').gen_samples(np.max(n))\n",
        "        if order==8:\n",
        "          unif_rqmc = qmcpy.Lattice(d+1,z_path=z_path+'lattice_vec.600.13.npy').gen_samples(np.max(n))\n",
        "      else:\n",
        "        if sobol:\n",
        "          unif_rqmc = qmcpy.Sobol(d+1).gen_samples(np.max(n))\n",
        "        else:\n",
        "          unif_rqmc = qmcpy.Halton(d+1).gen_samples(np.max(n))\n",
        "    # even number of parameters\n",
        "    else: \n",
        "      if lattice:\n",
        "        if order==1:\n",
        "          unif_rqmc = qmcpy.Lattice(d).gen_samples(np.max(n))\n",
        "        if order==2:\n",
        "          unif_rqmc = qmcpy.Lattice(d,z_path=z_path+'lattice_vec.600.20.npy').gen_samples(np.max(n))\n",
        "        if order==8:\n",
        "          unif_rqmc = qmcpy.Lattice(d,z_path=z_path+'lattice_vec.600.13.npy').gen_samples(np.max(n))\n",
        "      else:\n",
        "        if sobol:\n",
        "          unif_rqmc = qmcpy.Sobol(d).gen_samples(np.max(n))\n",
        "        else:\n",
        "          unif_rqmc = qmcpy.Halton(d).gen_samples(np.max(n))\n",
        "        \n",
        "    x = gen_gaussian(np.max(n),d,unif_rqmc,theta,s)\n",
        "    x_rqmc[r,:,:] = x\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahkv7xNxUdyd"
      },
      "source": [
        "def sample_gaussian_r_d(n,num,d,s,theta,lattice=False,order=1,sobol=False, z_path=None):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc or qmc_1 sequence have to be fixed before using this function   '\n",
        "\n",
        "  # MC\n",
        "  x_mc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    # odd number of parameters\n",
        "    if np.max(d) % 2 != 0: \n",
        "      unif_mc = np.random.rand(n,np.max(d)+1)\n",
        "    # even number of parameters\n",
        "    else: \n",
        "      unif_mc = np.random.rand(n,np.max(d))\n",
        "    x = gen_gaussian(n,np.max(d),unif_mc,theta,s)\n",
        "    x_mc[r,:,:] = x\n",
        "\n",
        "  # QMC\n",
        "  # odd number of parameters\n",
        "  if np.max(d) % 2 != 0: \n",
        "    unif_qmc = qmc_1.gen_samples(n)\n",
        "  # even number of parameters\n",
        "  else: \n",
        "    unif_qmc = qmc.gen_samples(n)\n",
        "  x_qmc = gen_gaussian(n,np.max(d),unif_qmc,theta,s)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    # odd number of parameters\n",
        "    if np.max(d) % 2 != 0: \n",
        "      if lattice:\n",
        "        if order==1:\n",
        "          unif_rqmc = qmcpy.Lattice(np.max(d)+1).gen_samples(n)\n",
        "        if order==2:\n",
        "          unif_rqmc = qmcpy.Lattice(np.max(d)+1,z_path=z_path+'lattice_vec.600.20.npy').gen_samples(n)\n",
        "        if order==8:\n",
        "          unif_rqmc = qmcpy.Lattice(np.max(d)+1,z_path=z_path+'lattice_vec.600.13.npy').gen_samples(n)\n",
        "      else:\n",
        "        if sobol:\n",
        "          unif_rqmc = qmcpy.Sobol(np.max(d)+1).gen_samples(n)\n",
        "        else:\n",
        "          unif_rqmc = qmcpy.Halton(np.max(d)+1).gen_samples(n)\n",
        "    # even number of parameters\n",
        "    else: \n",
        "      if lattice:\n",
        "        if order==1:\n",
        "          unif_rqmc = qmcpy.Lattice(np.max(d)).gen_samples(n)\n",
        "        if order==2:\n",
        "          unif_rqmc = qmcpy.Lattice(np.max(d),z_path=z_path+'lattice_vec.600.20.npy').gen_samples(n)\n",
        "        if order==8:\n",
        "          unif_rqmc = qmcpy.Lattice(np.max(d),z_path=z_path+'lattice_vec.600.13.npy').gen_samples(n)\n",
        "      else:\n",
        "        if sobol:\n",
        "          unif_rqmc = qmcpy.Sobol(np.max(d)).gen_samples(n)\n",
        "        else:\n",
        "          unif_rqmc = qmcpy.Halton(np.max(d)).gen_samples(n)\n",
        "    x = gen_gaussian(n,np.max(d),unif_rqmc,theta,s)\n",
        "    x_rqmc[r,:,:] = x\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpsvFtX2HZ9O"
      },
      "source": [
        "def sample_gaussian_r_inv(n,num,d,s,theta,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function   '\n",
        "\n",
        "  # MC\n",
        "  x_mc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(np.max(n),d)\n",
        "    x = gen_gaussian_inv(np.max(n),d,unif_mc,theta,s)\n",
        "    x_mc[r,:,:] = x\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(np.max(n))\n",
        "  x_qmc = gen_gaussian_inv(np.max(n),d,unif_qmc,theta,s)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    if lattice:\n",
        "      if order==1:\n",
        "        unif_rqmc = qmcpy.Lattice(d).gen_samples(np.max(n))\n",
        "      if order==2:\n",
        "        unif_rqmc = qmcpy.Lattice(d,z_path=z_path+'lattice_vec.600.20.npy').gen_samples(np.max(n))\n",
        "      if order==8:\n",
        "        unif_rqmc = qmcpy.Lattice(d,z_path=z_path+'lattice_vec.600.13.npy').gen_samples(np.max(n))\n",
        "    else:\n",
        "      if sobol:\n",
        "        unif_rqmc = qmcpy.Sobol(d).gen_samples(np.max(n))\n",
        "      else:\n",
        "        unif_rqmc = qmcpy.Halton(d).gen_samples(np.max(n))\n",
        "    x = gen_gaussian_inv(np.max(n),d,unif_rqmc,theta,s)\n",
        "    x_rqmc[r,:,:] = x\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bfn-NMyVK0O"
      },
      "source": [
        "def sample_gaussian_r_inv_d(n,num,d,s,theta,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function   '\n",
        "\n",
        "  # MC\n",
        "  x_mc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(n,np.max(d))\n",
        "    x = gen_gaussian_inv(n,np.max(d),unif_mc,theta,s)\n",
        "    x_mc[r,:,:] = x\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(n)\n",
        "  x_qmc = gen_gaussian_inv(n,np.max(d),unif_qmc,theta,s)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    if lattice:\n",
        "      if order==1:\n",
        "        unif_rqmc = qmcpy.Lattice(np.max(d)).gen_samples(n)\n",
        "      if order==2:\n",
        "        unif_rqmc = qmcpy.Lattice(np.max(d),z_path=z_path+'lattice_vec.600.20.npy').gen_samples(n)\n",
        "      if order==8:\n",
        "        unif_rqmc = qmcpy.Lattice(np.max(d),z_path=z_path+'lattice_vec.600.13.npy').gen_samples(n)\n",
        "    else:\n",
        "      if sobol:\n",
        "        unif_rqmc = qmcpy.Sobol(np.max(d)).gen_samples(n)\n",
        "      else:\n",
        "        unif_rqmc = qmcpy.Halton(np.max(d)).gen_samples(n)\n",
        "    x = gen_gaussian_inv(n,np.max(d),unif_rqmc,theta,s)\n",
        "    x_rqmc[r,:,:] = x\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXZWOL4-aWMc"
      },
      "source": [
        "Function to sample from **g-and-k distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZaSWerPacba"
      },
      "source": [
        "def sample_gandk(method_sampling,n,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  # generate uniforms\n",
        "  if method_sampling == 'MC':\n",
        "    unif = np.random.rand(n,d+1)\n",
        "  if method_sampling == 'QMC':\n",
        "    unif = qmc.gen_samples(n)\n",
        "  if method_sampling == 'RQMC':\n",
        "    unif = qmcpy.Halton(d+1).gen_samples(n)\n",
        "\n",
        "  # generate standard normals  \n",
        "  z = normals(n,d,unif)\n",
        "\n",
        "  # generate samples from g-and-k distribution\n",
        "  x = gen_gandk(z,theta)\n",
        "\n",
        "  return list([x,z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxJLkA0zu2Y6"
      },
      "source": [
        "def sample_gandk_inv(method_sampling,n,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  # generate uniforms\n",
        "  if method_sampling == 'MC':\n",
        "    unif = np.random.rand(n,d)\n",
        "  if method_sampling == 'QMC':\n",
        "    unif = qmc.gen_samples(n)\n",
        "  if method_sampling == 'RQMC':\n",
        "    unif = qmcpy.Halton(d).gen_samples(n)\n",
        "\n",
        "  # generate standard normals  \n",
        "  z = normals_inv(unif)\n",
        "\n",
        "  # generate samples from g-and-k distribution\n",
        "  x = gen_gandk(z,theta)\n",
        "\n",
        "  return list([x,z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS9a5y2IxbvZ"
      },
      "source": [
        "Function to sample from **multivariate g-and-k distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkYAqNEOxbvZ"
      },
      "source": [
        "def sample_mvgandk(method_sampling,n,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  # generate uniforms\n",
        "  if method_sampling == 'MC':\n",
        "    unif = np.random.rand(n,d+1)\n",
        "  if method_sampling == 'QMC':\n",
        "    unif = qmc.gen_samples(n)\n",
        "  if method_sampling == 'RQMC':\n",
        "    unif = qmcpy.Halton(d+1).gen_samples(n)\n",
        "\n",
        "  # generate standard normals  \n",
        "  z = normals(n,d,unif)\n",
        "\n",
        "  # generate samples from g-and-k distribution\n",
        "  x = gen_mvgandk(z,theta)\n",
        "\n",
        "  return list([x,z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b08L8ckqxbva"
      },
      "source": [
        "def sample_mvgandk_inv(method_sampling,n,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  # generate uniforms\n",
        "  if method_sampling == 'MC':\n",
        "    unif = np.random.rand(n,d)\n",
        "  if method_sampling == 'QMC':\n",
        "    unif = qmc.gen_samples(n)\n",
        "  if method_sampling == 'RQMC':\n",
        "    unif = qmcpy.Halton(d).gen_samples(n)\n",
        "\n",
        "  # generate standard normals  \n",
        "  z = normals_inv(unif)\n",
        "\n",
        "  # generate samples from g-and-k distribution\n",
        "  x = gen_mvgandk(z,theta)\n",
        "\n",
        "  return list([x,z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKgluUDWbIJ3"
      },
      "source": [
        "Function to sample $R$-times for MC and RQMC from **g-and-k distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qPWkaRDbHH2"
      },
      "source": [
        "def sample_gandk_r(n,num,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  #MC\n",
        "  x_mc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(np.max(n),d+1)\n",
        "    z = normals(np.max(n), d, unif_mc)\n",
        "    x_mc[r,:,:] = gen_gandk(z,theta)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(np.max(n))\n",
        "  z = normals(np.max(n), d, unif_qmc)\n",
        "  x_qmc = gen_gandk(z,theta)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_rqmc = qmcpy.Halton(d+1).gen_samples(np.max(n))\n",
        "    z = normals(np.max(n), d, unif_rqmc)\n",
        "    x_rqmc[r,:,:] = gen_gandk(z,theta)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jvJCP0zu7yU"
      },
      "source": [
        "def sample_gandk_r_inv(n,num,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  #MC\n",
        "  x_mc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(np.max(n),d)\n",
        "    z = normals_inv(unif_mc)\n",
        "    x_mc[r,:,:] = gen_gandk(z,theta)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(np.max(n))\n",
        "  z = normals_inv(unif_qmc)\n",
        "  x_qmc = gen_gandk(z,theta)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_rqmc = qmcpy.Halton(d).gen_samples(np.max(n))\n",
        "    z = normals_inv(unif_rqmc)\n",
        "    x_rqmc[r,:,:] = gen_gandk(z,theta)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPikiSCExori"
      },
      "source": [
        "Function to sample $R$-times for MC and RQMC from **multivariate g-and-k distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2yIZ0Hrxori"
      },
      "source": [
        "def sample_mvgandk_r(n,num,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  #MC\n",
        "  x_mc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(np.max(n),d+1)\n",
        "    z = normals(np.max(n), d, unif_mc)\n",
        "    x_mc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(np.max(n))\n",
        "  z = normals(np.max(n), d, unif_qmc)\n",
        "  x_qmc = gen_mvgandk(z,theta)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_rqmc = qmcpy.Halton(d+1).gen_samples(np.max(n))\n",
        "    z = normals(np.max(n), d, unif_rqmc)\n",
        "    x_rqmc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppwpu-ckxorj"
      },
      "source": [
        "def sample_mvgandk_r_inv(n,num,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  #MC\n",
        "  x_mc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(np.max(n),d)\n",
        "    z = normals_inv(unif_mc)\n",
        "    x_mc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(np.max(n))\n",
        "  z = normals_inv(unif_qmc)\n",
        "  x_qmc = gen_mvgandk(z,theta)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,np.max(n),d))\n",
        "  for r in range(num):\n",
        "    unif_rqmc = qmcpy.Halton(d).gen_samples(np.max(n))\n",
        "    z = normals_inv(unif_rqmc)\n",
        "    x_rqmc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bRg5zo9m32u"
      },
      "source": [
        "def sample_mvgandk_r_d(n,num,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  #MC\n",
        "  x_mc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(n,np.max(d)+1)\n",
        "    z = normals(n, np.max(d), unif_mc)\n",
        "    x_mc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(np.max(d)+1)\n",
        "  z = normals(n, np.max(d), unif_qmc)\n",
        "  x_qmc = gen_mvgandk(z,theta)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    unif_rqmc = qmcpy.Halton(np.max(d)+1).gen_samples(n)\n",
        "    z = normals(n, np.max(d), unif_rqmc)\n",
        "    x_rqmc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOO5iOR8m326"
      },
      "source": [
        "def sample_mvgandk_r_inv_d(n,num,d,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  #MC\n",
        "  x_mc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    unif_mc = np.random.rand(n,np.max(d))\n",
        "    z = normals_inv(unif_mc)\n",
        "    x_mc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  # QMC\n",
        "  unif_qmc = qmc.gen_samples(n)\n",
        "  z = normals_inv(unif_qmc)\n",
        "  x_qmc = gen_mvgandk(z,theta)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,n,np.max(d)))\n",
        "  for r in range(num):\n",
        "    unif_rqmc = qmcpy.Halton(np.max(d)).gen_samples(n)\n",
        "    z = normals_inv(unif_rqmc)\n",
        "    x_rqmc[r,:,:] = gen_mvgandk(z,theta)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvNMdR6HiUTa"
      },
      "source": [
        "Function to sample from **bivariate beta distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsOdmjGlibbg"
      },
      "source": [
        "def sample_bibeta(method_sampling,n,theta):\n",
        "\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  # split theta into integer and decimal parts\n",
        "  i_theta,_ = divmod(theta,np.ones(5)) \n",
        "  p = np.sum(i_theta.astype(int))\n",
        "\n",
        "  # sample uniforms\n",
        "  if method_sampling == 'MC':\n",
        "    unif = np.random.rand(n,p)\n",
        "  if method_sampling == 'QMC':\n",
        "    unif = qmc.gen_samples(n)\n",
        "  if method_sampling == 'RQMC':\n",
        "    unif = qmcpy.Halton(p).gen_samples(n)\n",
        "\n",
        "  # generate samples\n",
        "  if method_sampling == 'QMC' or method_sampling == 'RQMC':\n",
        "    x = gen_bibeta(theta,unif,qmc_gamma=True)\n",
        "  else: \n",
        "    x = gen_bibeta(theta,unif)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gAWq9shkpDf"
      },
      "source": [
        "Funktion to sample $R$-times for MC and RQMC from **bivariate beta distribution**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg25JbLakzY5"
      },
      "source": [
        " def sample_bibeta_r(n,num,theta):\n",
        "  ' caveat:                                                                 '\n",
        "  ' the qmc sequence has to be fixed before using this function             '\n",
        "\n",
        "  # split theta into integer and decimal parts\n",
        "  i_theta,_ = divmod(theta,np.ones(5)) \n",
        "  p = np.sum(i_theta.astype(int))\n",
        "\n",
        "  #MC\n",
        "  x_mc = np.zeros((num,np.max(n),2))\n",
        "  for r in range(num):\n",
        "    unif = np.random.rand(np.max(n),p)\n",
        "    x_mc[r,:,:] = gen_bibeta(theta,unif)\n",
        "\n",
        "  # QMC\n",
        "  unif = qmc.gen_samples(np.max(n))\n",
        "  x_qmc = gen_bibeta(theta,unif,qmc_gamma=True)\n",
        "\n",
        "  # RQMC\n",
        "  x_rqmc = np.zeros((num,np.max(n),2))\n",
        "  for r in range(num):\n",
        "    unif = qmcpy.Halton(p).gen_samples(np.max(n))\n",
        "    x_rqmc[r,:,:] = gen_bibeta(theta,unif,qmc_gamma=True)\n",
        "\n",
        "  return list([x_mc,x_qmc,x_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOVrhiWKRPFu"
      },
      "source": [
        "## Optimisation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWiP716aFJRc"
      },
      "source": [
        "def optim(model,method_sampling,method_gd,eta,max_it,l,c,b,nu,n,m,d,p,y,start,stat_type,kernel='gaussian',s=2,sparse=False):\n",
        "\n",
        "  ' caveat:                                                                '\n",
        "  ' the qmc sequence has to be fixed before using this function            '\n",
        "  \n",
        "  ' function arguments:                                                    '   \n",
        "  ' model:             \"gaussian\" or \"gandk\" or \"sv\"                       '\n",
        "  ' method_sampling:   \"MC\" or \"QMC\" or \"RQMC\"                             '\n",
        "  ' method_sg:         \"SGD\" or \"NSGD\"                                     '\n",
        "  ' eta:               step size                                           '\n",
        "  ' max_it:            maximum number of iterations                        '\n",
        "  ' l:                 lengthscale of the Gaussian kernel                  '\n",
        "  ' c:                 parameter c of the IMQ kernel                       '\n",
        "  ' b:                 parameter beta of the IMQ kernel                    '\n",
        "  ' n:                 number of samples simulated per iteration           '\n",
        "  ' m:                 number of true samples                              '\n",
        "  ' d:                 number of dimensions                                '\n",
        "  ' y:                 true data set                                       '\n",
        "  ' start:             start values                                        '\n",
        "  ' kernel (optional): \"gaussian\" or \"imq\"                                 '\n",
        "  ' s (optional):      standard deviation in Gaussian location model       '\n",
        "  ' sparse (optional): True or False                                       '\n",
        "\n",
        "  # median heuristic if l=-1\n",
        "  if l == -1:\n",
        "    l = np.sqrt((1/2)*np.median(distance.cdist(y,y,'sqeuclidean')))\n",
        "\n",
        "  # pre-define noise for information metric\n",
        "  noise = [0, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
        "\n",
        "  # pre-compute the kernel and its derivatives for the true data points\n",
        "  kyy = k(y,y,kernel,l,c,b,nu,grad=False,sparse=True)\n",
        "  \n",
        "  # list for squared MMD\n",
        "  loss = []  \n",
        "\n",
        "  # start values\n",
        "  theta = np.expand_dims(start,axis=0) \n",
        "\n",
        "  # create timer instance\n",
        "  t = TicToc()\n",
        "  t.tic()\n",
        "\n",
        "  for i in range(max_it):\n",
        "    \n",
        "    # simulate data using the current estimate for theta\n",
        "    if model == 'gaussian':\n",
        "      x = sample_gaussian(method_sampling,n,d,s,theta[i,:])\n",
        "    if model == 'gandk':\n",
        "      x,z = sample_gandk(method_sampling,n,d,theta[i,:])\n",
        "    \n",
        "    # calculate kernel and the derivatives\n",
        "    kxx = k(x,x,kernel,l,c,b,nu,sparse=False)\n",
        "    kxy = k(x,y,kernel,l,c,b,nu,sparse=False)\n",
        "    \n",
        "    # calculate the gradient of the generator\n",
        "    if model == 'gaussian':\n",
        "      grad_g = grad_gen_gaussian(n,theta[i,:])\n",
        "    if model == 'gandk':\n",
        "      grad_g = grad_gen_gandk(z, theta[i,:])\n",
        "    \n",
        "    # approximate squared MMD gradient\n",
        "    if p==1:\n",
        "      J = np.asmatrix(grad_MMD(p,n,m,grad_g,kxx[1],kxy[1],stat_type))\n",
        "    else:\n",
        "      J = grad_MMD(p,n,m,grad_g,kxx[1],kxy[1],stat_type)\n",
        "    \n",
        "    # approximate information metric\n",
        "    if method_gd == 'NSGD':\n",
        "      g = g_approx(p,n,grad_g,kxx[2])\n",
        "      # add noise if g can't be inverted\n",
        "      for j in range(9):\n",
        "        check = True\n",
        "        try:\n",
        "          np.linalg.inv(g + np.eye(p)*noise[j])\n",
        "        except np.linalg.LinAlgError:\n",
        "          check = False\n",
        "        if check:\n",
        "          break\n",
        "      g = g + np.eye(p)*noise[j]\n",
        "    \n",
        "    # update estimate for theta using NSGD or SGD\n",
        "    if method_gd == 'NSGD':\n",
        "        theta = np.vstack([theta,theta[i,:]-eta*np.linalg.inv(g)@J]) # NSGD\n",
        "    else:\n",
        "        theta = np.vstack([theta,theta[i,:]-eta*J]) # SGD\n",
        "    \n",
        "    # calculate current squared MMD approximation\n",
        "    loss.append(MMD_approx(n,m,kxx[0],kxy[0],kyy[0],stat_type))\n",
        "    \n",
        "    # print outputs\n",
        "    if (i+1)%1000 == 0:\n",
        "        print('iteration:',i+1,'\\nloss:     ', round(loss[i],7),'\\nestimate: ',theta[i+1,:],'\\ngradient: ', J)\n",
        "\n",
        "    # stop if nan occurs\n",
        "    if np.isnan(loss[i]):\n",
        "      break\n",
        "\n",
        "  print('-------------------------------------------\\nfinal loss:       ', round(loss[i],7), '\\nfinal estimate:   ', theta[i+1,:],'\\ntotal iterations: ',i+1)\n",
        "  t.toc() \n",
        "\n",
        "  np.savetxt(fname=method_sampling+'_theta.csv', delimiter=\",\", X=theta)\n",
        "  np.savetxt(fname=method_sampling+'_loss.csv', delimiter=\",\", X=loss)\n",
        "\n",
        "  return list([theta, loss])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J8ygjVl2XUU"
      },
      "source": [
        "def optim_inv_nosub(model,method_sampling,method_gd,eta,max_it,l,c,b,nu,n,m,d,p,y,start,stat_type,kernel='gaussian',s=2):\n",
        "\n",
        "  ' function uses inverse transform instead of Box-Muller transform        '\n",
        "\n",
        "  ' caveat:                                                                '\n",
        "  ' the qmc sequence has to be fixed before using this function            '\n",
        "  \n",
        "  ' function arguments:                                                    '   \n",
        "  ' model:             \"gaussian\" or \"gandk\" or \"sv\"                       '\n",
        "  ' method_sampling:   \"MC\" or \"QMC\" or \"RQMC\"                             '\n",
        "  ' method_sg:         \"SGD\" or \"NSGD\"                                     '\n",
        "  ' eta:               step size                                           '\n",
        "  ' max_it:            maximum number of iterations                        '\n",
        "  ' l:                 lengthscale of the Gaussian kernel                  '\n",
        "  ' c:                 parameter c of the IMQ kernel                       '\n",
        "  ' b:                 parameter beta of the IMQ kernel                    '\n",
        "  ' n:                 number of samples simulated per iteration           '\n",
        "  ' m:                 number of true samples                              '\n",
        "  ' d:                 number of dimensions                                '\n",
        "  ' y:                 true data set                                       '\n",
        "  ' start:             start values                                        '\n",
        "  ' kernel (optional): \"gaussian\" or \"imq\"                                 '\n",
        "  ' s (optional):      standard deviation in Gaussian location model       '\n",
        "  ' sparse (optional): True or False                                       '\n",
        "\n",
        "  # median heuristic if l=-1\n",
        "  if l == -1:\n",
        "    l = np.sqrt((1/2)*np.median(distance.cdist(y,y,'sqeuclidean')))\n",
        "\n",
        "  # pre-define noise for information metric\n",
        "  noise = [0, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
        "\n",
        "  # pre-compute the kernel and its derivatives for the true data points\n",
        "  kyy = k(y,y,kernel,l,c,b,nu,grad=False,sparse=True)\n",
        "  \n",
        "  # list for squared MMD\n",
        "  loss = []  \n",
        "\n",
        "  # start values\n",
        "  theta = np.expand_dims(start,axis=0) \n",
        "\n",
        "  # create timer instance\n",
        "  t = TicToc()\n",
        "  t.tic()\n",
        "\n",
        "  for i in range(max_it):\n",
        "    \n",
        "    # simulate data using the current estimate for theta\n",
        "    if model == 'gaussian':\n",
        "      x = sample_gaussian_inv(method_sampling,n,d,s,theta[i,:])\n",
        "    if model == 'gandk':\n",
        "      x,z = sample_gandk_inv(method_sampling,n,d,theta[i,:])\n",
        "    if model == 'mvgandk':\n",
        "      x,z = sample_mvgandk_inv(method_sampling,n,d,theta[i,:])\n",
        "    \n",
        "    # calculate kernel and the derivatives\n",
        "    kxx = k(x,x,kernel,l,c,b,nu,sparse=False)\n",
        "    kxy = k(x,y,kernel,l,c,b,nu,sparse=False)\n",
        "    \n",
        "    # calculate the gradient of the generator\n",
        "    if model == 'gaussian':\n",
        "      grad_g = grad_gen_gaussian(n,theta[i,:])\n",
        "    if model == 'gandk':\n",
        "      grad_g = grad_gen_gandk(z, theta[i,:])\n",
        "    if model == 'mvgandk':\n",
        "      grad_g = grad_gen_mvgandk(z, theta[i,:])\n",
        "    \n",
        "    # approximate squared MMD gradient\n",
        "    if p==1:\n",
        "      J = np.asmatrix(grad_MMD(p,n,m,grad_g,kxx[1],kxy[1],stat_type))\n",
        "    else:\n",
        "      J = grad_MMD(p,n,m,grad_g,kxx[1],kxy[1],stat_type)\n",
        "    \n",
        "    # approximate information metric\n",
        "    if method_gd == 'NSGD':\n",
        "      g = g_approx(p,n,grad_g,kxx[2])\n",
        "      # add noise if g can't be inverted\n",
        "      for j in range(9):\n",
        "        check = True\n",
        "        try:\n",
        "          np.linalg.inv(g + np.eye(p)*noise[j])\n",
        "        except np.linalg.LinAlgError:\n",
        "          check = False\n",
        "        if check:\n",
        "          break\n",
        "      g = g + np.eye(p)*noise[j]\n",
        "    \n",
        "    # update estimate for theta using NSGD or SGD\n",
        "    if method_gd == 'NSGD':\n",
        "        theta = np.vstack([theta,theta[i,:]-eta*np.linalg.inv(g)@J]) # NSGD\n",
        "    else:\n",
        "        theta = np.vstack([theta,theta[i,:]-eta*J]) # SGD\n",
        "    \n",
        "    # calculate current squared MMD approximation\n",
        "    loss.append(MMD_approx(n,m,kxx[0],kxy[0],kyy[0],stat_type))\n",
        "    \n",
        "    # print outputs\n",
        "    if (i+1)%1000 == 0:\n",
        "        print('iteration:',i+1,'\\nloss:     ', round(loss[i],7),'\\nestimate: ',theta[i+1,:],'\\ngradient: ', J)\n",
        "\n",
        "    # stop if nan occurs\n",
        "    if np.isnan(loss[i]):\n",
        "      break\n",
        "\n",
        "  print('-------------------------------------------\\nfinal loss:       ', round(loss[i],7), '\\nfinal estimate:   ', theta[i+1,:],'\\ntotal iterations: ',i+1)\n",
        "  t.toc() \n",
        "\n",
        "  np.savetxt(fname=method_sampling+'_theta.csv', delimiter=\",\", X=theta)\n",
        "  np.savetxt(fname=method_sampling+'_loss.csv', delimiter=\",\", X=loss)\n",
        "\n",
        "  return list([theta, loss])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pckqXNUFy7Ud"
      },
      "source": [
        "def optim_inv(model,method_sampling,method_gd,eta,max_it,l,c,b,nu,n,m,d,p,y,start,stat_type,kernel='gaussian',s=2):\n",
        "\n",
        "  ' function uses inverse transform instead of Box-Muller transform        '\n",
        "\n",
        "  ' caveat:                                                                '\n",
        "  ' the qmc sequence has to be fixed before using this function            '\n",
        "  \n",
        "  ' function arguments:                                                    '   \n",
        "  ' model:             \"gaussian\" or \"gandk\" or \"sv\"                       '\n",
        "  ' method_sampling:   \"MC\" or \"QMC\" or \"RQMC\"                             '\n",
        "  ' method_sg:         \"SGD\" or \"NSGD\"                                     '\n",
        "  ' eta:               step size                                           '\n",
        "  ' max_it:            maximum number of iterations                        '\n",
        "  ' l:                 lengthscale of the Gaussian kernel                  '\n",
        "  ' c:                 parameter c of the IMQ kernel                       '\n",
        "  ' b:                 parameter beta of the IMQ kernel                    '\n",
        "  ' n:                 number of samples simulated per iteration           '\n",
        "  ' m:                 number of true samples                              '\n",
        "  ' d:                 number of dimensions                                '\n",
        "  ' y:                 true data set                                       '\n",
        "  ' start:             start values                                        '\n",
        "  ' kernel (optional): \"gaussian\" or \"imq\"                                 '\n",
        "  ' s (optional):      standard deviation in Gaussian location model       '\n",
        "  ' sparse (optional): True or False                                       '\n",
        "\n",
        "  # median heuristic if l=-1\n",
        "  if l == -1:\n",
        "    l = np.sqrt((1/2)*np.median(distance.cdist(y,y,'sqeuclidean')))\n",
        "\n",
        "  # pre-define noise for information metric\n",
        "  noise = [0, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
        "  \n",
        "  # list for squared MMD\n",
        "  loss = []  \n",
        "\n",
        "  # start values\n",
        "  theta = np.expand_dims(start,axis=0) \n",
        "\n",
        "  # create timer instance\n",
        "  t = TicToc()\n",
        "  t.tic()\n",
        "\n",
        "  for i in range(max_it):\n",
        "\n",
        "    # subsample from the true data\n",
        "    sub = np.random.choice(np.arange(y.shape[0]),m)\n",
        "    y_sub = y[sub,:]\n",
        "    \n",
        "    # simulate data using the current estimate for theta\n",
        "    if model == 'gaussian':\n",
        "      x = sample_gaussian_inv(method_sampling,n,d,s,theta[i,:])\n",
        "    if model == 'gandk':\n",
        "      x,z = sample_gandk_inv(method_sampling,n,d,theta[i,:])\n",
        "    if model == 'mvgandk':\n",
        "      x,z = sample_mvgandk_inv(method_sampling,n,d,theta[i,:])\n",
        "    \n",
        "    # calculate kernel and the derivatives\n",
        "    kyy = k(y_sub,y_sub,kernel,l,c,b,nu,grad=False,sparse=False)\n",
        "    kxx = k(x,x,kernel,l,c,b,nu,sparse=False)\n",
        "    kxy = k(x,y_sub,kernel,l,c,b,nu,sparse=False)\n",
        "    \n",
        "    # calculate the gradient of the generator\n",
        "    if model == 'gaussian':\n",
        "      grad_g = grad_gen_gaussian(n,theta[i,:])\n",
        "    if model == 'gandk':\n",
        "      grad_g = grad_gen_gandk(z, theta[i,:])\n",
        "    if model == 'mvgandk':\n",
        "      grad_g = grad_gen_mvgandk(z, theta[i,:])\n",
        "    \n",
        "    # approximate squared MMD gradient\n",
        "    if p==1:\n",
        "      J = np.asmatrix(grad_MMD(p,n,m,grad_g,kxx[1],kxy[1],stat_type))\n",
        "    else:\n",
        "      J = grad_MMD(p,n,m,grad_g,kxx[1],kxy[1],stat_type)\n",
        "    \n",
        "    # approximate information metric\n",
        "    if method_gd == 'NSGD':\n",
        "      g = g_approx(p,n,grad_g,kxx[2])\n",
        "      # add noise if g can't be inverted\n",
        "      for j in range(9):\n",
        "        check = True\n",
        "        try:\n",
        "          np.linalg.inv(g + np.eye(p)*noise[j])\n",
        "        except np.linalg.LinAlgError:\n",
        "          check = False\n",
        "        if check:\n",
        "          break\n",
        "      g = g + np.eye(p)*noise[j]\n",
        "    \n",
        "    # update estimate for theta using NSGD or SGD\n",
        "    if method_gd == 'NSGD':\n",
        "        theta = np.vstack([theta,theta[i,:]-eta*np.linalg.inv(g)@J]) # NSGD\n",
        "    else:\n",
        "        theta = np.vstack([theta,theta[i,:]-eta*J]) # SGD\n",
        "    \n",
        "    # calculate current squared MMD approximation\n",
        "    loss.append(MMD_approx(n,m,kxx[0],kxy[0],kyy[0],stat_type))\n",
        "    \n",
        "    # print outputs\n",
        "    if (i+1)%1000 == 0:\n",
        "        print('iteration:',i+1,'\\nloss:     ', round(loss[i],7),'\\nestimate: ',theta[i+1,:],'\\ngradient: ', J)\n",
        "\n",
        "    # stop if nan occurs\n",
        "    if np.isnan(loss[i]):\n",
        "      break\n",
        "\n",
        "  print('-------------------------------------------\\nfinal loss:       ', round(loss[i],7), '\\nfinal estimate:   ', theta[i+1,:],'\\ntotal iterations: ',i+1)\n",
        "  t.toc() \n",
        "\n",
        "  np.savetxt(fname=method_sampling+'_theta.csv', delimiter=\",\", X=theta)\n",
        "  np.savetxt(fname=method_sampling+'_loss.csv', delimiter=\",\", X=loss)\n",
        "\n",
        "  return list([theta, loss])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia3NwvLMWdM7"
      },
      "source": [
        "### MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x7DYFCKWecF"
      },
      "source": [
        "def mse(max_it,p,theta1,theta3,theta_star):\n",
        "  mse1 = np.zeros((max_it-1,p))\n",
        "  mse3 = np.zeros((max_it-1,p))\n",
        "  for l in range(p):\n",
        "    for j in range(max_it-1):\n",
        "      mse1[j,l] = np.mean(np.asarray((theta1[1:j+2,l]-theta_star[l]))**2)\n",
        "      mse3[j,l] = np.mean(np.asarray((theta3[1:j+2,l]-theta_star[l]))**2)\n",
        "  return list([mse1,mse3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRnQs6-mdDAN"
      },
      "source": [
        "## Convergence of MMD$^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxNaepO2dIqI"
      },
      "source": [
        "Function to calculate MMD$^2$ against $n$ for uniform distribution, Gaussian distribution, g-and-k distribution and bivariate beta distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFdN0pLZEj4O"
      },
      "source": [
        "def mmd_conv(model,n,num,d,l,c,b,nu,kernel='gaussian',stat_type='v',theta=None,s=2,mc_all=False,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,lattice,order,sobol,z_path)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r(n,num,d,theta)\n",
        "  if model == 'gandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gandk_r(n,num,d,theta)\n",
        "  \n",
        "  # median heuristic if l=-1\n",
        "  if l == -1:\n",
        "    l = np.sqrt((1/2)*np.median(distance.cdist(x_qmc,x_qmc,'sqeuclidean')))\n",
        "\n",
        "  # calculate squared MMD for a sequence of n\n",
        "  MMD_mc = []\n",
        "  MMD_qmc = []\n",
        "  MMD_rqmc = []\n",
        "  MMD_min_mc = []\n",
        "  MMD_max_mc = []\n",
        "  MMD_min_rqmc = []\n",
        "  MMD_max_rqmc = []\n",
        "  MMD_all_mc = []\n",
        "  for j in n:\n",
        "\n",
        "    # R repetitions for MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      mc_ave.append(MMD_approx(j,j,k(x_mc[r,:j,:],x_mc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_mc[r,:j,:],y_mc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_mc[r,:j,:],y_mc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "      rqmc_ave.append(MMD_approx(j,j,k(x_rqmc[r,:j,:],x_rqmc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_rqmc[r,:j,:],y_rqmc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_rqmc[r,:j,:],y_rqmc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "\n",
        "    if mc_all:\n",
        "      # append all values for MC\n",
        "      MMD_all_mc.append(np.array(mc_ave))\n",
        "\n",
        "    # append min and max values for MC and RQMC\n",
        "    MMD_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    MMD_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    MMD_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    MMD_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave))))\n",
        "\n",
        "    # append value for QMC and mean values for MC and RQMC\n",
        "    MMD_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    MMD_qmc.append(MMD_approx(j,j,k(x_qmc[:j,:],x_qmc[:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_qmc[:j,:],y_qmc[:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_qmc[:j,:],y_qmc[:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "    MMD_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  if mc_all:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc,MMD_all_mc])\n",
        "  else:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtVJ635-1AQ8"
      },
      "source": [
        "def mmd_conv_inv(model,n,num,d,l,c,b,nu,kernel,stat_type,theta=None,s=2,mc_all=False,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,lattice,order,sobol,z_path)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_inv(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_inv(n,num,d,theta)\n",
        "  if model == 'gandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gandk_r_inv(n,num,d,theta)\n",
        "\n",
        "  # median heuristic if l=-1\n",
        "  if l == -1:\n",
        "    l = np.sqrt((1/2)*np.median(distance.cdist(x_qmc,x_qmc,'sqeuclidean')))\n",
        "\n",
        "  # calculate squared MMD for a sequence of n\n",
        "  MMD_mc = []\n",
        "  MMD_qmc = []\n",
        "  MMD_rqmc = []\n",
        "  MMD_min_mc = []\n",
        "  MMD_max_mc = []\n",
        "  MMD_min_rqmc = []\n",
        "  MMD_max_rqmc = []\n",
        "  MMD_all_mc = []\n",
        "  for j in n:\n",
        "\n",
        "    # R repetitions for MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      mc_ave.append(MMD_approx(j,j,k(x_mc[r,:j,:],x_mc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_mc[r,:j,:],y_mc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_mc[r,:j,:],y_mc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "      rqmc_ave.append(MMD_approx(j,j,k(x_rqmc[r,:j,:],x_rqmc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_rqmc[r,:j,:],y_rqmc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_rqmc[r,:j,:],y_rqmc[r,:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type)) \n",
        "    \n",
        "    if mc_all:\n",
        "      # append all values for MC\n",
        "      MMD_all_mc.append(np.array(mc_ave))\n",
        "\n",
        "    # append min and max values for MC and RQMC\n",
        "    MMD_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    MMD_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    MMD_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    MMD_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave))))\n",
        "\n",
        "    # append value for QMC and mean values for MC and RQMC\n",
        "    MMD_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    MMD_qmc.append(MMD_approx(j,j,k(x_qmc[:j,:],x_qmc[:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_qmc[:j,:],y_qmc[:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_qmc[:j,:],y_qmc[:j,:],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "    MMD_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  if mc_all:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc,MMD_all_mc])\n",
        "  else:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAFkBL4KMwDw"
      },
      "source": [
        "Function to calculate MMD$^2$ against $d$ with fixed $n$ for uniform distribution, Gaussian distribution and g-and-k distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjiS7za6OdPm"
      },
      "source": [
        "def mmd_conv_d(model,n,num,d,l,c,b,nu,kernel,stat_type,theta=None,s=2,mc_all=False,ladapt=False,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,lattice,order,sobol,z_path)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_d(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_d(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "  if model=='mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_d(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_d(n,num,d,theta)\n",
        "\n",
        "  # median heuristic if l=-1\n",
        "  if l == -1:\n",
        "    l = np.sqrt((1/2)*np.median(distance.cdist(x_qmc,x_qmc,'sqeuclidean')))\n",
        "\n",
        "  # calculate squared MMD for a sequence of n\n",
        "  MMD_mc = []\n",
        "  MMD_qmc = []\n",
        "  MMD_rqmc = []\n",
        "  MMD_min_mc = []\n",
        "  MMD_max_mc = []\n",
        "  MMD_min_rqmc = []\n",
        "  MMD_max_rqmc = []\n",
        "  MMD_all_mc = []\n",
        "  for j in d:\n",
        "\n",
        "    # R repetitions for MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      if ladapt:\n",
        "        mc_ave.append(MMD_approx(n,n,k(x_mc[r,:,:j],x_mc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(x_mc[r,:,:j],y_mc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(y_mc[r,:,:j],y_mc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "        rqmc_ave.append(MMD_approx(n,n,k(x_rqmc[r,:,:j],x_rqmc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(x_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(y_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],stat_type)) \n",
        "      else:\n",
        "        mc_ave.append(MMD_approx(n,n,k(x_mc[r,:,:j],x_mc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_mc[r,:,:j],y_mc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_mc[r,:,:j],y_mc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "        rqmc_ave.append(MMD_approx(n,n,k(x_rqmc[r,:,:j],x_rqmc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type)) \n",
        "\n",
        "    if mc_all:\n",
        "      # append all values for MC\n",
        "      MMD_all_mc.append(np.array(mc_ave))\n",
        "\n",
        "    # append min and max values for MC and RQMC\n",
        "    MMD_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    MMD_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    MMD_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    MMD_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave))))\n",
        "\n",
        "    # append value for QMC and mean values for MC and RQMC\n",
        "    MMD_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    if ladapt:\n",
        "      MMD_qmc.append(MMD_approx(n,n,k(x_qmc[:,:j],x_qmc[:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(x_qmc[:,:j],y_qmc[:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(y_qmc[:,:j],y_qmc[:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "    else:\n",
        "      MMD_qmc.append(MMD_approx(n,n,k(x_qmc[:,:j],x_qmc[:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_qmc[:,:j],y_qmc[:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_qmc[:,:j],y_qmc[:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "    MMD_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    print('number of dimensions: ', j)\n",
        "\n",
        "  if mc_all:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc,MMD_all_mc])\n",
        "  else:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKHOzpYbMtos"
      },
      "source": [
        "def mmd_conv_inv_d(model,n,num,d,l,c,b,nu,kernel,stat_type,theta=None,s=2,mc_all=False,ladapt=False,lattice=False,order=1,sobol=False,z_path=None):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,lattice,order,sobol,z_path)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,lattice,order,sobol,z_path)\n",
        "  if model=='mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_inv_d(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_inv_d(n,num,d,theta)\n",
        "\n",
        "  # median heuristic if l=-1\n",
        "  if l == -1:\n",
        "    l = np.sqrt((1/2)*np.median(distance.cdist(x_qmc,x_qmc,'sqeuclidean')))\n",
        "\n",
        "  # calculate squared MMD for a sequence of n\n",
        "  MMD_mc = []\n",
        "  MMD_qmc = []\n",
        "  MMD_rqmc = []\n",
        "  MMD_min_mc = []\n",
        "  MMD_max_mc = []\n",
        "  MMD_min_rqmc = []\n",
        "  MMD_max_rqmc = []\n",
        "  MMD_all_mc = []\n",
        "  for j in d:\n",
        "\n",
        "    # R repetitions for MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      if ladapt:\n",
        "        mc_ave.append(MMD_approx(n,n,k(x_mc[r,:,:j],x_mc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(x_mc[r,:,:j],y_mc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(y_mc[r,:,:j],y_mc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "        rqmc_ave.append(MMD_approx(n,n,k(x_rqmc[r,:,:j],x_rqmc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(x_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(y_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],stat_type)) \n",
        "      else:\n",
        "        mc_ave.append(MMD_approx(n,n,k(x_mc[r,:,:j],x_mc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_mc[r,:,:j],y_mc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_mc[r,:,:j],y_mc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "        rqmc_ave.append(MMD_approx(n,n,k(x_rqmc[r,:,:j],x_rqmc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_rqmc[r,:,:j],y_rqmc[r,:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type)) \n",
        "    \n",
        "    if mc_all:\n",
        "      # append all values for MC\n",
        "      MMD_all_mc.append(np.array(mc_ave))\n",
        "\n",
        "    # append min and max values for MC and RQMC\n",
        "    MMD_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    MMD_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    MMD_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    MMD_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave))))\n",
        "\n",
        "    # append value for QMC and mean values for MC and RQMC\n",
        "    MMD_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    if ladapt:\n",
        "      MMD_qmc.append(MMD_approx(n,n,k(x_qmc[:,:j],x_qmc[:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(x_qmc[:,:j],y_qmc[:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],k(y_qmc[:,:j],y_qmc[:,:j],kernel,l*np.sqrt(j),c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "    else:\n",
        "      MMD_qmc.append(MMD_approx(n,n,k(x_qmc[:,:j],x_qmc[:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(x_qmc[:,:j],y_qmc[:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],k(y_qmc[:,:j],y_qmc[:,:j],kernel,l,c,b,nu,grad=False,sparse=True)[0],stat_type))\n",
        "    MMD_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    print('number of dimensions: ', j)\n",
        "\n",
        "  if mc_all:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc,MMD_all_mc])\n",
        "  else:\n",
        "    return list([MMD_mc,MMD_qmc,MMD_rqmc,MMD_min_mc,MMD_max_mc,MMD_min_rqmc,MMD_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64W_HOMQ-arO"
      },
      "source": [
        "### Convergence of Wasserstein distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUq7P3DzAf3W"
      },
      "source": [
        "Function to calculate Wasserstein distance against $n$ for uniform distribution, Gaussian distribution, g-and-k distribution and bivariate beta distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETAEbzx9-d_R"
      },
      "source": [
        " def W_conv(model,n,num,d,theta=None,s=2,cost='euclidean',sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r(n,num,d,s,theta,sobol=sobol)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'gandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gandk_r(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gandk_r(n,num,d,theta)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in n:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((j,)) / j \n",
        "    b = np.ones((j,)) / j\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      M = ot.dist(x_mc[r,:j,:], y_mc[r,:j,:], cost)\n",
        "      M /= M.max()\n",
        "      mc_ave.append(ot.emd2(a, b, M))\n",
        "      M = ot.dist(x_rqmc[r,:j,:], y_rqmc[r,:j,:], cost)\n",
        "      M /= M.max()\n",
        "      rqmc_ave.append(ot.emd2(a, b, M))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    M = ot.dist(x_qmc[:j,:], y_qmc[:j,:], cost)\n",
        "    M /= M.max()\n",
        "    W_qmc.append(np.abs(ot.emd2(a, b, M)))\n",
        "\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjn0QquO1IQc"
      },
      "source": [
        " def W_conv_inv(model,n,num,d,theta=None,s=2,cost='euclidean',sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,sobol=sobol)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'gandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gandk_r_inv(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gandk_r_inv(n,num,d,theta)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in n:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((j,)) / j \n",
        "    b = np.ones((j,)) / j\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      M = ot.dist(x_mc[r,:j,:], y_mc[r,:j,:], cost)\n",
        "      M /= M.max()\n",
        "      mc_ave.append(ot.emd2(a, b, M))\n",
        "      M = ot.dist(x_rqmc[r,:j,:], y_rqmc[r,:j,:], cost)\n",
        "      M /= M.max()\n",
        "      rqmc_ave.append(ot.emd2(a, b, M))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    M = ot.dist(x_qmc[:j,:], y_qmc[:j,:], cost)\n",
        "    M /= M.max()\n",
        "    W_qmc.append(np.abs(ot.emd2(a, b, M)))\n",
        "\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIHiDgYgiRBW"
      },
      "source": [
        "Function to calculate Wasserstein distance against $d$ for uniform distribution and Gaussian distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsSAO1EPiWrG"
      },
      "source": [
        " def W_conv_d(model,n,num,d,theta=None,s=2,cost='euclidean',sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_d(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_d(n,num,d,s,theta,sobol=sobol)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in d:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((n,)) / n \n",
        "    b = np.ones((n,)) / n\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      M = ot.dist(x_mc[r,:,:j], y_mc[r,:,:j], cost)\n",
        "      M /= M.max()\n",
        "      mc_ave.append(ot.emd2(a, b, M))\n",
        "      M = ot.dist(x_rqmc[r,:,:j], y_rqmc[r,:,:j], cost)\n",
        "      M /= M.max()\n",
        "      rqmc_ave.append(ot.emd2(a, b, M))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    M = ot.dist(x_qmc[:,:j], y_qmc[:,:j], cost)\n",
        "    M /= M.max()\n",
        "    W_qmc.append(np.abs(ot.emd2(a, b, M)))\n",
        "\n",
        "    print('Number of dimensions: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_CKzbLhicr2"
      },
      "source": [
        " def W_conv_inv_d(model,n,num,d,theta=None,s=2,cost='euclidean',sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,sobol=sobol)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in d:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((n,)) / n \n",
        "    b = np.ones((n,)) / n\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      M = ot.dist(x_mc[r,:,:j], y_mc[r,:,:j], cost)\n",
        "      M /= M.max()\n",
        "      mc_ave.append(ot.emd2(a, b, M))\n",
        "      M = ot.dist(x_rqmc[r,:,:j], y_rqmc[r,:,:j], cost)\n",
        "      M /= M.max()\n",
        "      rqmc_ave.append(ot.emd2(a, b, M))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    M = ot.dist(x_qmc[:,:j], y_qmc[:,:j], cost)\n",
        "    M /= M.max()\n",
        "    W_qmc.append(np.abs(ot.emd2(a, b, M)))\n",
        "\n",
        "    print('Number of dimensions: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdc9IAS8AnVk"
      },
      "source": [
        "### Convergence of Sinkhorn divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ztPL45Asks"
      },
      "source": [
        "Function to calculate Sinkhorn divergence against $n$ for uniform distribution, Gaussian distribution, bivariate beta distribution and g-and-k distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLuFs6ADRtUG"
      },
      "source": [
        "def sink_conv(model,n,num,d,e,theta=None,s=2, method='sinkhorn',cost='sqeuclidean',sobol=False):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r(n,num,d,s,theta,sobol=sobol)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r(n,num,d,theta)\n",
        "  if model == 'gandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gandk_r(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gandk_r(n,num,d,theta)\n",
        "\n",
        "  # calculate Sinkhorn distance for a sequence of n\n",
        "  sink_qmc = []\n",
        "  sink_mc = []\n",
        "  sink_rqmc = []\n",
        "  sink_min_mc = []\n",
        "  sink_max_mc = []\n",
        "  sink_min_rqmc = []\n",
        "  sink_max_rqmc = []\n",
        "  for j in n:\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((j,)) / j  \n",
        "    b = np.ones((j,)) / j\n",
        "\n",
        "    #MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      mc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_mc[r,:j,:], y_mc[r,:j,:], e, a, b, cost, method=method))\n",
        "      rqmc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_rqmc[r,:j,:], y_rqmc[r,:j,:], e, a, b, cost, method=method))\n",
        "\n",
        "    # QMC\n",
        "    sink_qmc.append(ot.bregman.empirical_sinkhorn_divergence(x_qmc[:j,:], y_qmc[:j,:], e, a, b, cost, method=method))\n",
        "\n",
        "    # calculate mean Sinkhorn loss for MC and RQMC\n",
        "    sink_mc.append(np.mean(np.array(mc_ave)))\n",
        "    sink_rqmc.append(np.mean(np.array(rqmc_ave)))\n",
        "\n",
        "    # calculate min and max values for MC and RQMC\n",
        "    sink_max_mc.append(np.squeeze(np.max(np.array(mc_ave))))\n",
        "    sink_min_mc.append(np.squeeze(np.min(np.array(mc_ave))))\n",
        "    sink_max_rqmc.append(np.squeeze(np.max(np.array(rqmc_ave))))\n",
        "    sink_min_rqmc.append(np.squeeze(np.min(np.array(rqmc_ave))))\n",
        "\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  return list([sink_mc,sink_qmc,sink_rqmc,sink_min_mc,sink_max_mc,sink_min_rqmc,sink_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV9PCN4nZXIP"
      },
      "source": [
        "def sink_conv_inv(model,n,num,d,e,theta=None,s=2, method='sinkhorn',cost='sqeuclidean',sobol=False):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,sobol=sobol)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_inv(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_inv(n,num,d,theta)\n",
        "  if model == 'gandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gandk_r_inv(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gandk_r_inv(n,num,d,theta)\n",
        "\n",
        "  # calculate Sinkhorn distance for a sequence of n\n",
        "  sink_qmc = []\n",
        "  sink_mc = []\n",
        "  sink_rqmc = []\n",
        "  sink_min_mc = []\n",
        "  sink_max_mc = []\n",
        "  sink_min_rqmc = []\n",
        "  sink_max_rqmc = []\n",
        "  for j in n:\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((j,)) / j  \n",
        "    b = np.ones((j,)) / j\n",
        "\n",
        "    #MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      mc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_mc[r,:j,:], y_mc[r,:j,:], e, a, b, cost, method=method))\n",
        "      rqmc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_rqmc[r,:j,:], y_rqmc[r,:j,:], e, a, b, cost, method=method))\n",
        "\n",
        "    # QMC\n",
        "    sink_qmc.append(ot.bregman.empirical_sinkhorn_divergence(x_qmc[:j,:], y_qmc[:j,:], e, a, b, cost, method=method))\n",
        "\n",
        "    # calculate mean Sinkhorn loss for MC and RQMC\n",
        "    sink_mc.append(np.mean(np.array(mc_ave)))\n",
        "    sink_rqmc.append(np.mean(np.array(rqmc_ave)))\n",
        "\n",
        "    # calculate min and max values for MC and RQMC\n",
        "    sink_max_mc.append(np.squeeze(np.max(np.array(mc_ave))))\n",
        "    sink_min_mc.append(np.squeeze(np.min(np.array(mc_ave))))\n",
        "    sink_max_rqmc.append(np.squeeze(np.max(np.array(rqmc_ave))))\n",
        "    sink_min_rqmc.append(np.squeeze(np.min(np.array(rqmc_ave))))\n",
        "\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  return list([sink_mc,sink_qmc,sink_rqmc,sink_min_mc,sink_max_mc,sink_min_rqmc,sink_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwnY4JqfihLm"
      },
      "source": [
        "Function to calculate Sinkhorn loss against $d$ for uniform distribution, Gaussian distribution and g-and-k distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA60kZRCvDYw"
      },
      "source": [
        "def sink_conv_d(model,n,num,d,e,theta=None,s=2,eadapt=False,method='sinkhorn',cost='sqeuclidean',sobol=False):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_d(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_d(n,num,d,s,theta,sobol=sobol)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_d(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_d(n,num,d,theta)\n",
        "\n",
        "  # calculate Sinkhorn distance for a sequence of n\n",
        "  sink_qmc = []\n",
        "  sink_mc = []\n",
        "  sink_rqmc = []\n",
        "  sink_min_mc = []\n",
        "  sink_max_mc = []\n",
        "  sink_min_rqmc = []\n",
        "  sink_max_rqmc = []\n",
        "  for j in d:\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((n,)) / n  \n",
        "    b = np.ones((n,)) / n\n",
        "\n",
        "    #MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      if eadapt:\n",
        "        mc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_mc[r,:,:j], y_mc[r,:,:j], e*j, a, b, cost, method=method))\n",
        "        rqmc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_rqmc[r,:,:j], y_rqmc[r,:,:j], e*j, a, b, cost, method=method))\n",
        "      else:\n",
        "        mc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_mc[r,:,:j], y_mc[r,:,:j], e, a, b, cost, method=method))\n",
        "        rqmc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_rqmc[r,:,:j], y_rqmc[r,:,:j], e, a, b, cost, method=method))\n",
        "\n",
        "    # QMC\n",
        "    if eadapt:\n",
        "      sink_qmc.append(ot.bregman.empirical_sinkhorn_divergence(x_qmc[:,:j], y_qmc[:,:j], e*j, a, b, cost, method=method))\n",
        "    else:\n",
        "      sink_qmc.append(ot.bregman.empirical_sinkhorn_divergence(x_qmc[:,:j], y_qmc[:,:j], e, a, b, cost, method=method))\n",
        "\n",
        "    # calculate mean Sinkhorn loss for MC and RQMC\n",
        "    sink_mc.append(np.mean(np.array(mc_ave)))\n",
        "    sink_rqmc.append(np.mean(np.array(rqmc_ave)))\n",
        "\n",
        "    # calculate min and max values for MC and RQMC\n",
        "    sink_max_mc.append(np.squeeze(np.max(np.array(mc_ave))))\n",
        "    sink_min_mc.append(np.squeeze(np.min(np.array(mc_ave))))\n",
        "    sink_max_rqmc.append(np.squeeze(np.max(np.array(rqmc_ave))))\n",
        "    sink_min_rqmc.append(np.squeeze(np.min(np.array(rqmc_ave))))\n",
        "\n",
        "    print('number of dimensions: ', j)\n",
        "\n",
        "  return list([sink_mc,sink_qmc,sink_rqmc,sink_min_mc,sink_max_mc,sink_min_rqmc,sink_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRdIOvi-vJqi"
      },
      "source": [
        "def sink_conv_inv_d(model,n,num,d,e,theta=None,s=2,eadapt=False, method='sinkhorn',cost='sqeuclidean',sobol=False):\n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,sobol=sobol)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_inv_d(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_inv_d(n,num,d,theta)\n",
        "\n",
        "  # calculate Sinkhorn distance for a sequence of n\n",
        "  sink_qmc = []\n",
        "  sink_mc = []\n",
        "  sink_rqmc = []\n",
        "  sink_min_mc = []\n",
        "  sink_max_mc = []\n",
        "  sink_min_rqmc = []\n",
        "  sink_max_rqmc = []\n",
        "  for j in d:\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((n,)) / n  \n",
        "    b = np.ones((n,)) / n\n",
        "\n",
        "    #MC and RQMC\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "    for r in range(num):\n",
        "      if eadapt:\n",
        "        mc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_mc[r,:,:j], y_mc[r,:,:j], e*j, a, b, cost, method=method))\n",
        "        rqmc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_rqmc[r,:,:j], y_rqmc[r,:,:j], e*j, a, b, cost, method=method))\n",
        "      else:\n",
        "        mc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_mc[r,:,:j], y_mc[r,:,:j], e, a, b, cost, method=method))\n",
        "        rqmc_ave.append(ot.bregman.empirical_sinkhorn_divergence(x_rqmc[r,:,:j], y_rqmc[r,:,:j], e, a, b, cost, method=method))\n",
        "\n",
        "    # QMC\n",
        "    if eadapt:\n",
        "      sink_qmc.append(ot.bregman.empirical_sinkhorn_divergence(x_qmc[:,:j], y_qmc[:,:j], e*j, a, b, cost, method=method))\n",
        "    else:\n",
        "      sink_qmc.append(ot.bregman.empirical_sinkhorn_divergence(x_qmc[:,:j], y_qmc[:,:j], e, a, b, cost, method=method))\n",
        "\n",
        "    # calculate mean Sinkhorn loss for MC and RQMC\n",
        "    sink_mc.append(np.mean(np.array(mc_ave)))\n",
        "    sink_rqmc.append(np.mean(np.array(rqmc_ave)))\n",
        "\n",
        "    # calculate min and max values for MC and RQMC\n",
        "    sink_max_mc.append(np.squeeze(np.max(np.array(mc_ave))))\n",
        "    sink_min_mc.append(np.squeeze(np.min(np.array(mc_ave))))\n",
        "    sink_max_rqmc.append(np.squeeze(np.max(np.array(rqmc_ave))))\n",
        "    sink_min_rqmc.append(np.squeeze(np.min(np.array(rqmc_ave))))\n",
        "\n",
        "    print('number of dimensions: ', j)\n",
        "\n",
        "  return list([sink_mc,sink_qmc,sink_rqmc,sink_min_mc,sink_max_mc,sink_min_rqmc,sink_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JkSDUdHd4lc"
      },
      "source": [
        "### Convergence of sliced Wasserstein distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmfZRTCddwRb"
      },
      "source": [
        "Function to calculate sliced Wasserstein distance against $n$ for uniform, Gaussian distribution bivariate beta distribution and g-and-k distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKKTX9HQdwRk"
      },
      "source": [
        " def slicedW_conv(model,n,num,d,n_projections,metric,theta=None,s=2,sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r(n,num,d,s,theta,sobol=sobol)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r(n,num,d,theta)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in n:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((j,)) / j \n",
        "    b = np.ones((j,)) / j\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      mc_ave.append(sliced_wasserstein_distance(x_mc[r,:j,:],y_mc[r,:j,:], metric, a, b, n_projections))\n",
        "      rqmc_ave.append(sliced_wasserstein_distance(x_rqmc[r,:j,:],y_rqmc[r,:j,:], metric, a, b, n_projections))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    W_qmc.append(np.abs(sliced_wasserstein_distance(x_qmc[:j,:],y_qmc[:j,:], metric, a, b, n_projections)))\n",
        "\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWiinm59dwRn"
      },
      "source": [
        " def slicedW_conv_inv(model,n,num,d,n_projections,metric,theta=None,s=2,sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv(n,num,d,s,theta,sobol=sobol)\n",
        "  if model=='bibeta':\n",
        "    x_mc,x_qmc,x_rqmc = sample_bibeta_r(n,num,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_bibeta_r(n,num,theta)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_inv(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_inv(n,num,d,theta)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in n:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((j,)) / j \n",
        "    b = np.ones((j,)) / j\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      mc_ave.append(sliced_wasserstein_distance(x_mc[r,:j,:],y_mc[r,:j,:], metric, a, b, n_projections))\n",
        "      rqmc_ave.append(sliced_wasserstein_distance(x_rqmc[r,:j,:],y_rqmc[r,:j,:], metric, a, b, n_projections))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    W_qmc.append(np.abs(sliced_wasserstein_distance(x_qmc[:j,:],y_qmc[:j,:], metric, a, b, n_projections)))\n",
        "\n",
        "    print('sample size: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DfERzrpdwRp"
      },
      "source": [
        "Function to calculate sliced Wasserstein distance against $d$ for uniform, Gaussian distribution and g-and-k distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vFdOW2OdwRq"
      },
      "source": [
        " def slicedW_conv_d(model,n,num,d,n_projections,metric,theta=None,s=2,sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_d(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_d(n,num,d,s,theta,sobol=sobol)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_d(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_d(n,num,d,theta)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in d:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((n,)) / n \n",
        "    b = np.ones((n,)) / n\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      mc_ave.append(sliced_wasserstein_distance(x_mc[r,:,:j],y_mc[r,:,:j], metric, a, b, n_projections))\n",
        "      rqmc_ave.append(sliced_wasserstein_distance(x_rqmc[r,:,:j],y_rqmc[r,:,:j], metric, a, b, n_projections))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    W_qmc.append(np.abs(sliced_wasserstein_distance(x_qmc[:,:j],y_qmc[:,:j], metric, a, b, n_projections)))\n",
        "\n",
        "    print('Number of dimensions: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aDcRrGcdwRt"
      },
      "source": [
        " def slicedW_conv_inv_d(model,n,num,d,n_projections,metric,theta=None,s=2,sobol=False): \n",
        "\n",
        "  # generate samples\n",
        "  if model=='unif':\n",
        "    x_mc,x_qmc,x_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_unif_r_d(n,num,d,sobol=sobol)\n",
        "  if model=='gaussian':\n",
        "    x_mc,x_qmc,x_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,sobol=sobol)\n",
        "    y_mc,y_qmc,y_rqmc = sample_gaussian_r_inv_d(n,num,d,s,theta,sobol=sobol)\n",
        "  if model == 'mvgandk':\n",
        "    x_mc,x_qmc,x_rqmc = sample_mvgandk_r_inv_d(n,num,d,theta)\n",
        "    y_mc,y_qmc,y_rqmc = sample_mvgandk_r_inv_d(n,num,d,theta)\n",
        "\n",
        "  # calculate Wasserstein distance for a sequence of n\n",
        "  W_mc = []\n",
        "  W_qmc = []\n",
        "  W_rqmc = []\n",
        "  W_min_mc = []\n",
        "  W_max_mc = []\n",
        "  W_min_rqmc = []\n",
        "  W_max_rqmc = []\n",
        "  for j in d:\n",
        "\n",
        "    mc_ave = []\n",
        "    rqmc_ave = []\n",
        "\n",
        "    # equal weights\n",
        "    a = np.ones((n,)) / n \n",
        "    b = np.ones((n,)) / n\n",
        "    \n",
        "    # MC and RQMC\n",
        "    for r in range(num):\n",
        "      mc_ave.append(sliced_wasserstein_distance(x_mc[r,:,:j],y_mc[r,:,:j], metric, a, b, n_projections))\n",
        "      rqmc_ave.append(sliced_wasserstein_distance(x_rqmc[r,:,:j],y_rqmc[r,:,:j], metric, a, b, n_projections))\n",
        "    W_mc.append(np.mean(np.abs(np.array(mc_ave))))\n",
        "    W_rqmc.append(np.mean(np.abs(np.array(rqmc_ave))))\n",
        "    \n",
        "    # append min and max values for MC and RQMC\n",
        "    W_min_mc.append(np.min(np.abs(np.array(mc_ave))))\n",
        "    W_max_mc.append(np.max(np.abs(np.array(mc_ave))))\n",
        "    W_min_rqmc.append(np.min(np.abs(np.array(rqmc_ave))))\n",
        "    W_max_rqmc.append(np.max(np.abs(np.array(rqmc_ave)))) \n",
        "\n",
        "    # QMC\n",
        "    W_qmc.append(np.abs(sliced_wasserstein_distance(x_qmc[:,:j],y_qmc[:,:j], metric, a, b, n_projections)))\n",
        "\n",
        "    print('Number of dimensions: ', j)\n",
        "\n",
        "  return list([W_mc,W_qmc,W_rqmc,W_min_mc,W_max_mc,W_min_rqmc,W_max_rqmc])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}